import json
import re
import sys
import os
from datetime import datetime, timedelta
from collections import defaultdict, Counter

# Ajustar sys.path para encontrar o módulo conecxaodb
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..', '..')))
try:
    from conecxaodb import get_connection
    import cx_Oracle
except ImportError:
    get_connection = None
    cx_Oracle = None

def get_db_connection():
    """Obtém conexão com o Oracle"""
    if get_connection:
        return get_connection()
    return None

class MemoriaConversacional:
    """Sistema de Memória Conversacional Inteligente usando Oracle"""
    
    def __init__(self):
        self.init_memory_tables()
        try:
            from ..TRAINING.passive_learner import PassiveLearner
            self.passive_learner = PassiveLearner()
        except ImportError:
            self.passive_learner = None
    
    def init_memory_tables(self):
        """Inicializa tabelas de memória conversacional no Oracle"""
        conn = get_db_connection()
        if not conn: return
        cursor = conn.cursor()
        
        try:
            # Tabela de perfil do usuário
            cursor.execute('''
            BEGIN
                EXECUTE IMMEDIATE 'CREATE TABLE SYSROH.TB_AI_USER_PROFILE (
                    ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                    USER_NAME VARCHAR2(100) NOT NULL UNIQUE,
                    PREFERENCES CLOB,
                    INTERACTION_STYLE VARCHAR2(50),
                    FAVORITE_METRICS CLOB,
                    RESPONSE_FORMAT VARCHAR2(50),
                    LAST_UPDATED TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )';
            EXCEPTION WHEN OTHERS THEN IF SQLCODE != -955 THEN RAISE; END IF;
            END;
            ''')
            
            # Tabela de contexto de problemas resolvidos
            cursor.execute('''
            BEGIN
                EXECUTE IMMEDIATE 'CREATE TABLE SYSROH.TB_AI_PROBLEM_CONTEXT (
                    ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                    USER_NAME VARCHAR2(100) NOT NULL,
                    PROBLEM_TYPE VARCHAR2(100),
                    SOLUTION_USED CLOB,
                    SQL_PATTERN CLOB,
                    SUCCESS_RATING NUMBER,
                    CREATED_AT TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )';
            EXCEPTION WHEN OTHERS THEN IF SQLCODE != -955 THEN RAISE; END IF;
            END;
            ''')
            
            # Tabela de padrões de linguagem
            cursor.execute('''
            BEGIN
                EXECUTE IMMEDIATE 'CREATE TABLE SYSROH.TB_AI_LANGUAGE_PATTERNS (
                    ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                    USER_NAME VARCHAR2(100) NOT NULL,
                    PHRASE_PATTERN VARCHAR2(500),
                    INTENT VARCHAR2(100),
                    FREQUENCY NUMBER DEFAULT 1,
                    LAST_USED TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )';
            EXCEPTION WHEN OTHERS THEN IF SQLCODE != -955 THEN RAISE; END IF;
            END;
            ''')
            
            # Tabela de memória contextual
            cursor.execute('''
            BEGIN
                EXECUTE IMMEDIATE 'CREATE TABLE SYSROH.TB_AI_CONTEXTUAL_MEMORY (
                    ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                    USER_NAME VARCHAR2(100) NOT NULL,
                    CONTEXT_TYPE VARCHAR2(50),
                    CONTENT CLOB NOT NULL,
                    IMPORTANCE NUMBER DEFAULT 1,
                    EXPIRES_AT TIMESTAMP,
                    CREATED_AT TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )';
            EXCEPTION WHEN OTHERS THEN IF SQLCODE != -955 THEN RAISE; END IF;
            END;
            ''')
            
            conn.commit()
        finally:
            cursor.close()
            conn.close()
    
    def analyze_user_patterns(self, user_name, days_back=30):
        """Analisa padrões do usuário nos últimos N dias"""
        conn = get_db_connection()
        if not conn: return {}
        cursor = conn.cursor()
        cursor.rowfactory = cx_Oracle.Row
        
        cutoff_date = datetime.now() - timedelta(days=days_back)
        
        # 1. Analisar perguntas frequentes
        cursor.execute('''
        SELECT m.CONTENT FROM SYSROH.TB_AI_CHAT_HISTORY m 
        JOIN SYSROH.TB_AI_CHATS c ON m.CHAT_ID = c.ID 
        WHERE c.USER_NAME = :uname AND m.ROLE = 'user' 
        AND m.CREATED_AT >= :cutoff
        ORDER BY m.CREATED_AT DESC
        ''', {'uname': user_name, 'cutoff': cutoff_date})
        
        user_queries = []
        for row in cursor.fetchall():
            content = row[0]
            if hasattr(content, 'read'):
                content = content.read()
            user_queries.append(content)
        
        # 2. Analisar respostas da IA para entender preferências
        cursor.execute('''
        SELECT m.CONTENT FROM SYSROH.TB_AI_CHAT_HISTORY m 
        JOIN SYSROH.TB_AI_CHATS c ON m.CHAT_ID = c.ID 
        WHERE c.USER_NAME = :uname AND m.ROLE = 'assistant' 
        AND m.CREATED_AT >= :cutoff
        ORDER BY m.CREATED_AT DESC
        ''', {'uname': user_name, 'cutoff': cutoff_date})
        
        ai_responses = []
        for row in cursor.fetchall():
            content = row[0]
            if hasattr(content, 'read'):
                content = content.read()
            ai_responses.append(content)
        
        cursor.close()
        conn.close()
        
        patterns = {
            'query_frequency': self._extract_query_patterns(user_queries),
            'format_preferences': self._analyze_format_preferences(ai_responses),
            'metrics_focus': self._extract_metrics_focus(user_queries + ai_responses),
            'interaction_style': self._determine_interaction_style(user_queries, ai_responses)
        }
        
        return patterns
    
    def _extract_query_patterns(self, queries):
        """Extrai padrões das consultas do usuário com detecção sofisticada"""
        patterns = Counter()
        
        # Mapeamento de sinônimos empresariais
        business_synonyms = {
            'cliente': ['cliente', 'contato', 'comprador', 'consumidor', 'pessoa'],
            'vendas': ['vendas', 'venda', 'vendeu', 'vendido', 'faturamento'],
            'financeiro': ['financeiro', 'dinheiro', 'caixa', 'financeira', 'contas'],
            'produto': ['produto', 'item', 'mercadoria', 'peça', 'serviço'],
            'pedido': ['pedido', 'encomenda', 'solicitação', 'requisição', 'ordem']
        }
        
        # Mapeamento de frases específicas para intenções
        phrase_intents = {
            'consulta_financeira': [
                'dinheiro em caixa', 'saldo', 'disponível', 'valor em caixa',
                'quanto tenho', 'total disponível', 'caixa atual'
            ],
            'comparativo': [
                'comparar', 'diferença', 'vs', 'contra', 'versus',
                'qual é melhor', 'mais que', 'menos que'
            ],
            'tendencia': [
                'tendência', 'tendencia', 'crescimento', 'queda', 'aumento',
                'diminuiu', 'subiu', 'evolução'
            ]
        }
        
        # Detecção de contexto temporal
        temporal_patterns = {
            'ontem': ['ontem', 'dia anterior', 'último dia'],
            'semana_passada': ['semana passada', 'última semana', 'semana anterior'],
            'mes_anterior': ['mês anterior', 'mês passado', 'último mês'],
            'hoje': ['hoje', 'agora', 'atualmente', 'neste momento']
        }
        
        for query in queries:
            query_lower = query.lower()
            
            # 1. Detectar sinônimos empresariais
            for main_term, synonyms in business_synonyms.items():
                if any(syn in query_lower for syn in synonyms):
                    patterns[main_term] += 1
            
            # 2. Detectar intenções específicas
            for intent, phrases in phrase_intents.items():
                if any(phrase in query_lower for phrase in phrases):
                    patterns[intent] += 1
            
            # 3. Detectar contexto temporal
            for temporal, time_phrases in temporal_patterns.items():
                if any(phrase in query_lower for phrase in time_phrases):
                    patterns[f'temporal_{temporal}'] += 1
            
            # 4. Detectar tipos de perguntas (mantido do original)
            if any(word in query_lower for word in ['qual', 'quantos', 'quantas', 'mostrar']):
                patterns['consulta_quantitativa'] += 1
            elif any(word in query_lower for word in ['prever', 'projeção', 'futuro', 'estimativa']):
                patterns['analise_preditiva'] += 1
            elif any(word in query_lower for word in ['problema', 'erro', 'defeito', 'issue']):
                patterns['problema_tecnico'] += 1
        
        return dict(patterns.most_common(15))
    
    def _analyze_format_preferences(self, responses):
        """Analisa preferências de formato das respostas"""
        format_count = Counter()
        
        for response in responses:
            if '|'.join(response.split()) in response or '---' in response:
                format_count['tabela'] += 1
            elif 'gráfico' in response.lower() or 'visual' in response.lower():
                format_count['grafico'] += 1
            elif len(response) < 200:
                format_count['resumo_curto'] += 1
            else:
                format_count['resumo_detalhado'] += 1
        
        return dict(format_count)
    
    def _extract_metrics_focus(self, texts):
        """Extrai métricas mais mencionadas"""
        metrics = Counter()
        
        metric_keywords = [
            'valor', 'total', 'média', 'quantidade', 'percentual', 'crescimento',
            'lucro', 'receita', 'custo', 'margem', 'estoque', 'vendas', 'clientes'
        ]
        
        for text in texts:
            for metric in metric_keywords:
                if metric in text.lower():
                    metrics[metric] += 1
        
        return dict(metrics.most_common(8))
    
    def _determine_interaction_style(self, queries, responses):
        """Determina o estilo de interação do usuário"""
        avg_query_length = sum(len(q.split()) for q in queries) / len(queries) if queries else 0
        formal_count = sum(1 for q in queries if any(word in q.lower() for word in ['por favor', 'gostaria', 'poderia']))
        
        if avg_query_length < 5:
            style = 'direto'
        elif formal_count > len(queries) * 0.3:
            style = 'formal'
        else:
            style = 'conversacional'
        
        return style
    
    def get_user_profile(self, user_name):
        """Recupera o perfil do usuário do Oracle"""
        conn = get_db_connection()
        if not conn: return {}
        cursor = conn.cursor()
        
        try:
            cursor.execute('SELECT * FROM SYSROH.TB_AI_USER_PROFILE WHERE USER_NAME = :uname', {'uname': user_name})
            row = cursor.fetchone()
            
            if not row:
                return {}
            
            columns = [col[0] for col in cursor.description]
            profile = dict(zip(columns, row))
            
            # Processar CLOBs e JSON
            for k, v in profile.items():
                if hasattr(v, 'read'):
                    profile[k] = v.read()
            
            if profile.get('PREFERENCES'):
                try:
                    profile['PREFERENCES'] = json.loads(profile['PREFERENCES'])
                except:
                    pass
            
            if profile.get('FAVORITE_METRICS'):
                try:
                    profile['FAVORITE_METRICS'] = json.loads(profile['FAVORITE_METRICS'])
                except:
                    pass
                    
            return profile
        finally:
            cursor.close()
            conn.close()

    def update_user_profile(self, user_name, preferences=None, interaction_style=None, favorite_metrics=None, response_format=None):
        """Atualiza o perfil do usuário com base nas análises ou dados fornecidos"""
        patterns = self.analyze_user_patterns(user_name) if not preferences else {}
        
        conn = get_db_connection()
        if not conn: return
        cursor = conn.cursor()
        
        try:
            # Usar valores fornecidos ou extraídos dos padrões
            prefs = json.dumps(preferences) if preferences else json.dumps(patterns)
            style = interaction_style if interaction_style else patterns.get('interaction_style', 'conversacional')
            metrics = json.dumps(favorite_metrics) if favorite_metrics else json.dumps(patterns.get('metrics_focus', {}))
            
            # Determinar formato de resposta
            if response_format:
                fmt = response_format
            elif patterns.get('format_preferences'):
                fmt = max(patterns.get('format_preferences', {}), key=patterns.get('format_preferences', {}).get)
            else:
                fmt = 'tabela'

            profile_data = {
                'uname': user_name,
                'prefs': prefs,
                'style': style,
                'metrics': metrics,
                'fmt': fmt
            }
            
            sql = """
                MERGE INTO SYSROH.TB_AI_USER_PROFILE t
                USING (SELECT :uname as un FROM dual) s
                ON (t.USER_NAME = s.un)
                WHEN MATCHED THEN
                    UPDATE SET 
                        PREFERENCES = :prefs, 
                        INTERACTION_STYLE = :style, 
                        FAVORITE_METRICS = :metrics, 
                        RESPONSE_FORMAT = :fmt,
                        LAST_UPDATED = CURRENT_TIMESTAMP
                WHEN NOT MATCHED THEN
                    INSERT (USER_NAME, PREFERENCES, INTERACTION_STYLE, FAVORITE_METRICS, RESPONSE_FORMAT)
                    VALUES (:uname, :prefs, :style, :metrics, :fmt)
            """
            cursor.execute(sql, profile_data)
            conn.commit()
        finally:
            cursor.close()
            conn.close()

    def get_user_memory_context(self, user_name):
        """Obtém contexto de memória para enriquecer o prompt"""
        conn = get_db_connection()
        if not conn: return ""
        cursor = conn.cursor()
        cursor.rowfactory = cx_Oracle.Row
        
        context = ""
        try:
            # 1. Perfil do usuário
            cursor.execute('SELECT INTERACTION_STYLE, RESPONSE_FORMAT FROM SYSROH.TB_AI_USER_PROFILE WHERE USER_NAME = :uname', {'uname': user_name})
            profile = cursor.fetchone()
            
            if profile:
                context += f"\n### PERFIL: {user_name} ###\n"
                context += f"Estilo: {profile['INTERACTION_STYLE'] or 'conversacional'}\n"
                context += f"Formato: {profile['RESPONSE_FORMAT'] or 'tabela'}\n"
            
            # 2. Memória mais importante apenas
            cursor.execute('''
            SELECT CONTENT FROM SYSROH.TB_AI_CONTEXTUAL_MEMORY 
            WHERE USER_NAME = :uname AND IMPORTANCE >= 3
            ORDER BY IMPORTANCE DESC, CREATED_AT DESC
            FETCH FIRST 1 ROWS ONLY
            ''', {'uname': user_name})
            
            top_memory = cursor.fetchone()
            if top_memory:
                content = top_memory[0]
                if hasattr(content, 'read'):
                    content = content.read()
                context += f"\n### MEMÓRIA ###\n{content}\n"
        finally:
            cursor.close()
            conn.close()
            
        return context
    
    def learn_contextual_fact(self, user_name, content, context_type='general', importance=1, expires_days=None):
        """Adiciona fato contextual à memória"""
        conn = get_db_connection()
        if not conn: return
        cursor = conn.cursor()
        
        try:
            expires_at = None
            if expires_days:
                expires_at = datetime.now() + timedelta(days=expires_days)
            
            cursor.execute('''
            INSERT INTO SYSROH.TB_AI_CONTEXTUAL_MEMORY (USER_NAME, CONTEXT_TYPE, CONTENT, IMPORTANCE, EXPIRES_AT)
            VALUES (:uname, :ctype, :content, :imp, :expires)
            ''', {'uname': user_name, 'ctype': context_type, 'content': content, 'imp': importance, 'expires': expires_at})
            
            conn.commit()
        finally:
            cursor.close()
            conn.close()
    
    def record_problem_solution(self, user_name, problem_type, solution_used, sql_pattern, success_rating):
        """Registra solução de problema para aprendizado futuro"""
        conn = get_db_connection()
        if not conn: return
        cursor = conn.cursor()
        
        try:
            cursor.execute('''
            INSERT INTO SYSROH.TB_AI_PROBLEM_CONTEXT (USER_NAME, PROBLEM_TYPE, SOLUTION_USED, SQL_PATTERN, SUCCESS_RATING)
            VALUES (:uname, :ptype, :sol, :sql, :rating)
            ''', {'uname': user_name, 'ptype': problem_type, 'sol': solution_used, 'sql': sql_pattern, 'rating': success_rating})
            
            conn.commit()
        finally:
            cursor.close()
            conn.close()
    
    def consolidate_memories(self, user_name):
        """Consolida memórias similares e resolve contradições"""
        conn = get_db_connection()
        if not conn: return
        cursor = conn.cursor()
        cursor.rowfactory = cx_Oracle.Row
        
        try:
            # 1. Buscar todas as memórias do usuário
            cursor.execute('''
            SELECT ID, CONTENT, CONTEXT_TYPE, IMPORTANCE, CREATED_AT 
            FROM SYSROH.TB_AI_CONTEXTUAL_MEMORY 
            WHERE USER_NAME = :uname AND (EXPIRES_AT IS NULL OR EXPIRES_AT > CURRENT_TIMESTAMP)
            ORDER BY CREATED_AT DESC
            ''', {'uname': user_name})
            
            memories = []
            for row in cursor.fetchall():
                m_dict = dict(zip([d[0] for d in cursor.description], row))
                if hasattr(m_dict['CONTENT'], 'read'):
                    m_dict['CONTENT'] = m_dict['CONTENT'].read()
                memories.append(m_dict)
            
            # 2. Agrupar memórias similares por similaridade de conteúdo
            memory_groups = []
            processed_ids = set()
            
            for memory in memories:
                if memory['ID'] in processed_ids:
                    continue
                    
                # Encontrar memórias similares
                similar_memories = [memory]
                for other_memory in memories:
                    if other_memory['ID'] in processed_ids or other_memory['ID'] == memory['ID']:
                        continue
                        
                    similarity_score = self._calculate_similarity(memory['CONTENT'], other_memory['CONTENT'])
                    if similarity_score > 0.7:  # 70% de similaridade
                        similar_memories.append(other_memory)
                        processed_ids.add(other_memory['ID'])
                
                processed_ids.add(memory['ID'])
                memory_groups.append(similar_memories)
            
            # 3. Processar cada grupo
            for group in memory_groups:
                if len(group) > 1:
                    # Consolidar grupo de memórias similares
                    self._consolidate_memory_group(user_name, group, cursor)
            
            # 4. Detectar contradições
            self._resolve_contradictions(user_name, cursor)
            
            conn.commit()
        finally:
            cursor.close()
            conn.close()
    
    def _calculate_similarity(self, text1, text2):
        """Calcula similaridade entre dois textos"""
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        return len(intersection) / len(union) if union else 0
    
    def _consolidate_memory_group(self, user_name, memory_group, cursor):
        """Consolida um grupo de memórias similares no Oracle"""
        if len(memory_group) <= 1:
            return
        
        # Manter a memória mais importante e recente
        consolidated = max(memory_group, key=lambda m: (m['IMPORTANCE'], m['CREATED_AT']))
        
        # Combinar conteúdos similares
        all_contents = [m['CONTENT'] for m in memory_group]
        unique_words = set()
        for content in all_contents:
            unique_words.update(content.lower().split())
        
        # Criar conteúdo consolidado
        consolidated_content = f"Consolidado: {' '.join(list(unique_words)[:10])}"
        
        # Aumentar importância baseada na frequência
        new_importance = min(5, consolidated['IMPORTANCE'] + len(memory_group) - 1)
        
        # Atualizar memória principal
        cursor.execute('''
        UPDATE SYSROH.TB_AI_CONTEXTUAL_MEMORY 
        SET CONTENT = :content, IMPORTANCE = :imp
        WHERE ID = :id
        ''', {'content': consolidated_content, 'imp': new_importance, 'id': consolidated['ID']})
        
        # Remover memórias duplicadas
        duplicate_ids = [m['ID'] for m in memory_group if m['ID'] != consolidated['ID']]
        if duplicate_ids:
            for d_id in duplicate_ids:
                cursor.execute('DELETE FROM SYSROH.TB_AI_CONTEXTUAL_MEMORY WHERE ID = :id', {'id': d_id})
    
    def _resolve_contradictions(self, user_name, cursor):
        """Detecta e resolve contradições nas preferências usando Oracle"""
        # Buscar preferências que podem contradizer
        cursor.execute('''
        SELECT CONTENT, IMPORTANCE FROM SYSROH.TB_AI_CONTEXTUAL_MEMORY 
        WHERE USER_NAME = :uname AND CONTEXT_TYPE = 'preference'
        AND (EXPIRES_AT IS NULL OR EXPIRES_AT > CURRENT_TIMESTAMP)
        ''', {'uname': user_name})
        
        preferences = []
        for row in cursor.fetchall():
            content = row[0]
            if hasattr(content, 'read'):
                content = content.read()
            preferences.append({'CONTENT': content, 'IMPORTANCE': row[1]})
        
        # Detectar contradições de formato
        format_preferences = {}
        for pref in preferences:
            content = pref['CONTENT'].lower()
            if 'tabela' in content:
                format_preferences['tabela'] = format_preferences.get('tabela', 0) + pref['IMPORTANCE']
            elif 'gráfico' in content:
                format_preferences['grafico'] = format_preferences.get('grafico', 0) + pref['IMPORTANCE']
            elif 'resumo' in content:
                format_preferences['resumo'] = format_preferences.get('resumo', 0) + pref['IMPORTANCE']
        
        # Se houver contradição, manter a preferência mais forte
        if len(format_preferences) > 1:
            strongest_format = max(format_preferences, key=format_preferences.get)
            
            # Remover preferências contraditórias
            for format_type in format_preferences:
                if format_type != strongest_format:
                    cursor.execute('''
                    DELETE FROM SYSROH.TB_AI_CONTEXTUAL_MEMORY 
                    WHERE USER_NAME = :uname AND CONTEXT_TYPE = 'preference' 
                    AND LOWER(CAST(CONTENT AS VARCHAR2(4000))) LIKE :fmt
                    ''', {'uname': user_name, 'fmt': f'%{format_type}%'})
            
            # Adicionar memória consolidada
            self.learn_contextual_fact(
                user_name, 
                f"Preferência consolidada: {strongest_format}", 
                'preference', 
                5,  # Máxima importância
                90  # Expira em 90 dias
            )
    
    def _analyze_sentiment(self, user_query, ai_response):
        """Analisa sentimento básico"""
        negative_words = ['ruim', 'errado', 'não gostei', 'horrível', 'péssimo', 'lento', 'erro']
        positive_words = ['bom', 'ótimo', 'excelente', 'parabéns', 'obrigado', 'vlw', 'ajudou']
        
        score = 0
        for word in negative_words:
            if word in user_query.lower():
                score -= 1
        for word in positive_words:
            if word in user_query.lower():
                score += 1
        return score

    def extract_learning_from_interaction(self, user_name, user_query, ai_response):
        """Extrai aprendizado automático da interação"""
        # Detectar preferências de formato
        if 'tabela' in user_query.lower() or '|'.join(ai_response.split()) in ai_response:
            self.learn_contextual_fact(user_name, "Prefere ver dados em formato de tabela", "preference", 3)
        
        # Detectar métricas importantes
        metrics = re.findall(r'\b(valor|total|média|quantidade|receita|lucro)\b', user_query.lower())
        for metric in metrics[:2]:
            self.learn_contextual_fact(user_name, f"Interesse em métricas de {metric}", "metric", 2)
        
        # Análise de sentimento
        sentiment_score = self._analyze_sentiment(user_query, ai_response)
        if sentiment_score < 0:
            self.learn_contextual_fact(user_name, "Possível insatisfação com resposta anterior", "feedback", 4, 30)

        if self._is_repeated_question(user_name, user_query):
            self.learn_contextual_fact(user_name, "Pergunta repetida - resposta anterior pode não ter sido clara", "feedback", 3, 15)
    
    def _analyze_sentiment(self, user_query, ai_response):
        """Análise de sentimento básica da interação"""
        user_lower = user_query.lower()
        
        # Indicadores positivos
        positive_indicators = [
            'obrigado', 'perfeito', 'excelente', 'ótimo', 'bom', 'ajudou',
            'funcionou', 'consegui', 'resolveu', 'show', 'legal'
        ]
        
        # Indicadores negativos
        negative_indicators = [
            'não', 'errado', 'erro', 'problema', 'dificuldade', 'não funcionou',
            'tentei', 'de novo', 'outra vez', 'não ajudou', 'confuso'
        ]
        
        # Contar indicadores
        positive_count = sum(1 for indicator in positive_indicators if indicator in user_lower)
        negative_count = sum(1 for indicator in negative_indicators if indicator in user_lower)
        
        # Calcular score simples (-1 a +1)
        total_indicators = positive_count + negative_count
        if total_indicators == 0:
            return 0  # Neutro
        
        return (positive_count - negative_count) / total_indicators
    
    def _is_repeated_question(self, user_name, current_query):
        """Verifica se a pergunta atual é similar a perguntas recentes"""
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Buscar perguntas recentes (últimas 24 horas)
        cursor.execute('''
        SELECT content FROM messages m
        JOIN chats c ON m.chat_id = c.id
        WHERE c.user_name = ? AND m.role = 'user'
        AND m.created_at >= datetime('now', '-1 day')
        ORDER BY m.created_at DESC
        LIMIT 10
        ''', (user_name,))
        
        recent_queries = [row['content'] for row in cursor.fetchall()]
        conn.close()
        
        # Verificar similaridade com perguntas recentes
        for query in recent_queries:
            similarity = self._calculate_similarity(current_query, query)
            if similarity > 0.8:  # 80% de similaridade indica repetição
                return True
        
        return False
    
    def auto_adjust_success_ratings(self, user_name):
        """Ajusta automaticamente success_rating baseado no feedback"""
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Buscar feedbacks recentes
        cursor.execute('''
        SELECT content, created_at FROM contextual_memory
        WHERE user_name = ? AND context_type = 'feedback'
        AND created_at >= datetime('now', '-7 days')
        ''', (user_name,))
        
        feedbacks = [dict(row) for row in cursor.fetchall()]
        
        # Analisar feedbacks para ajustar ratings
        for feedback in feedbacks:
            if 'insatisfação' in feedback['content'].lower():
                # Reduzir rating de problemas recentes
                cursor.execute('''
                UPDATE problem_context 
                SET success_rating = MAX(1, success_rating - 1)
                WHERE user_name = ? AND created_at >= datetime('now', '-3 days')
                ''', (user_name,))
            elif 'ajudou' in feedback['content'].lower() or 'perfeito' in feedback['content'].lower():
                # Aumentar rating de problemas recentes
                cursor.execute('''
                UPDATE problem_context 
                SET success_rating = MIN(5, success_rating + 1)
                WHERE user_name = ? AND created_at >= datetime('now', '-3 days')
                ''', (user_name,))
        
        conn.commit()
        conn.close()
    
    def extract_learning_from_interaction(self, user_name, user_query, ai_response):
        """Extrai aprendizado automático da interação com análise de sentimento (otimizado)"""
        # 1. Aprendizado Passivo Semântico (Novo sistema robusto)
        try:
            if self.passive_learner:
                self.passive_learner.analyze_interaction(user_name, user_query, ai_response)
        except Exception as e:
            print(f"Erro no aprendizado passivo: {e}")

        # 2. Detectar preferências de formato (legado/rápido)
        if 'tabela' in user_query.lower() and '|' in ai_response:
            self.learn_contextual_fact(user_name, "Prefere ver dados em formato de tabela", "preference", 3)
        
        # Detectar métricas importantes (limitado a 1 para performance)
        metrics = re.findall(r'\b(valor|total|média|quantidade|receita|lucro)\b', user_query.lower())
        if metrics:
            self.learn_contextual_fact(user_name, f"Interesse em métricas de {metrics[0]}", "metric", 2)
        
        # ANÁLISE DE SENTIMENTO BÁSICA (otimizada)
        sentiment_score = self._analyze_sentiment(user_query, ai_response)
        
        # Se detectar insatisfação, ajustar aprendizado
        if sentiment_score < 0:
            self.learn_contextual_fact(user_name, "Possível insatisfação com resposta anterior", "feedback", 4, 30)
        
        # Detectar padrão de repetição (apenas se for muito claro)
        if self._is_repeated_question(user_name, user_query):
            self.learn_contextual_fact(user_name, "Pergunta repetida - resposta anterior pode não ter sido clara", "feedback", 3, 15)
        
        # Detectar tipo de problema (simplificado)
        query_lower = user_query.lower()
        if any(word in query_lower for word in ['erro', 'problema', 'não funciona']):
            problem_type = "técnico"
        elif any(word in query_lower for word in ['comparar', 'diferença']):
            problem_type = "comparativo"
        elif any(word in query_lower for word in ['tendência', 'previsão']):
            problem_type = "preditivo"
        else:
            problem_type = "consulta"
        
        # Extrair padrão SQL se houver
        sql_match = re.search(r'\[SQL\](.*?)\[/SQL\]', ai_response, re.DOTALL | re.IGNORECASE)
        sql_pattern = sql_match.group(1).strip() if sql_match else None
        
        if sql_pattern and problem_type != "consulta":
            self.record_problem_solution(user_name, problem_type, ai_response[:200], sql_pattern, 4)
        
        # Consolidar memórias periodicamente (a cada 10 interações)
        import random
        if random.randint(1, 10) == 1:
            self.consolidate_memories(user_name)
        
        # Ajustar ratings baseado no feedback
        self.auto_adjust_success_ratings(user_name)

# Instância global para uso no sistema
memoria_system = MemoriaConversacional()
